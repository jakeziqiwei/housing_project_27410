---
title: "STAT 27410 Final Project Proposal"
author: "Brigette Kon and Jake Wei"
fontsize: 12pt
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
  geometry: margin=0.75in
fig_crop: no
---

```{r echo=FALSE, message=FALSE}
library(knitr)
knitr::opts_chunk$set(message=F, warning=F)
options(scipen=6, digits=6)
library(tidyverse)
library(ggplot2)
library(ggcorrplot)
library(mosaic)
library(car)
library(MASS)
library(broom)
library(xtable)
library(stargazer)
```

# 1. Introduction

Airbnb has become one of the most popular choices for people traveling and seeking housing. However, one problem exists. It is difficult for owners to come up with prices given the location and amenities. It is also hard to predict prices given seasons. Different features such as host ratings, season, location, and number of bedrooms make these two questions immensely complex. In this project, we try to provide insight into predicting prices given different neighborhoods in New York. The data set we picked comes from Inside Airbnb, which is an organization that periodically scrapes data from Airbnb listings. There are 12 columns in the data set. Four are descriptions of the host and 10 can serve as explanatory variables. The explanatory variables are: neighborhood, room_type, accommodation, bed, price, minimum nights, and number of reviews. The response variable is the rent price. Firstly, We will's start with exploratory analysis and data cleaning. Secondly, we'll use the frequentist approach to fit the data and analyze the models. Lastly, we'll describe how we are going to fit the model with respect to a Bayesian approach.   

We used R-Markdown to prepare this document. 

# 2. Exploratory Data Cleaning and Data Analysis


To start, we load our New York data from Inside Airbnb, and obtain the summary statistics on the numerical features.From the summary table, there are signs of outliers which we will do further analysis to confirm. The two most notable ones are 42 beds and 1250 minimum amounts of nights. 


```{r, results='asis'}

data <- read.csv('nydata.csv')

numerical_features <- data[3:9]
categorical_features <- data[10:11]
price = summary(as.data.frame(data$price))
num_and_price <- data[c(3:9,12)]

stargazer(num_and_price,type='latex', title = "Figure 1: Summary Stat for Numerical Features")
```



Next, we plot the density for each of the feature to get a sense of the shape. From the plots of each feature, there are signs of skewness from each other the features. The features are also poorly distributed. This also confirms our claim that there are outliers. The main outlier exist with minimum amounts stay, price, and amount of beds. To remedy this, we will remove the outliers according to the summary statistics in figure 1. 


```{r, echo=F, width=50%,height=50%}
features <- c("latitude", "longitude", "accommodates", "beds", "minimum_nights", "number_of_reviews", "review_scores_rating")


for (i in 1:ncol(numerical_features)) {
  p <- ggplot(numerical_features, aes(x = numerical_features[[i]])) +
    geom_density(fill = "skyblue", color = "black") +
    labs(title = paste("Density Plot of Feature", features[i]), x = features[i], y = "Density") +
    theme_minimal()
  
  plot(p)  # Print each plot
}

```


We clean the data by using two filters. The first one is to only look at listing that is under 500 dollars. The second one is that we only look at listings that have a minimum nights of under 30. We choose these two because of the distribution plots. Most data clustered around price less than or equal to 500 and minimum nights less than or equal to 30. Looking at figure 2, which is the summary stat for the cleaned data, and the density plots for the cleaned data, the skewness problem seems to be alleviated.  

```{r, echo=F}

#clean data
data_clean = subset(data,price <= 500 & minimum_nights <= 30)
numerical_features_clean <- data_clean[3:9]
categorical_features_clean <- data_clean[10:11]
price_clean <- data_clean$price

display <- data.frame(cbind(numerical_features_clean,price_clean))

stargazer(display,type='latex', title = "Figure 2: Summary Stat for Cleaned Numerical Features")


```



```{r, echo=F}

#graph again 

for (i in 1:ncol(numerical_features_clean)) {
  p <- ggplot(numerical_features_clean, aes(x = numerical_features_clean[[i]])) +
    geom_density(fill = "skyblue", color = "black") +
    labs(title = paste("Density Plot of Feature", features[i]), x = features[i], y = "Density") +
    theme_minimal()
  
  print(p)  # Print each plot
}

plot(price_clean)
```


Next, we check for correlation between the predictors. Because predictors such as number of reviews on a host might be correlated with other predictors that can reflect quality of housing , i.e number of beds and amenities, we want to make sure that our predictors does not show strong correlation. If our predictors are correlated, it can affect our model fit. To check, we created a correlation heat map of predictors. From figure 3, we see light correlation between some of the predictors. However, since no two predictor exhibit strong correlation, which is good. We will fit our model and analyze the model to see if our model is  good fit. 

```{r, echo=F}
pairs(numerical_features_clean)
cor_matrix <- cor(numerical_features_clean)
ggcorrplot(cor_matrix) + ggtitle("Figure 3: Correlation Heat Map")

```

To conclude our exploratory data analysis, we plot the relationship between neighborhood and price. From figure 5, we break down the prices by the neighborhood. Note that the graph only shows 30 neighborhoods because there are around 200 total neighborhoods in New York. We will insert the total in the appendix.  


```{r, echo=F}
#graphs with the categorical features 

ggplot(categorical_features_clean, aes(x = categorical_features_clean$room_type)) +
  geom_bar(stat = "count", fill = "skyblue", color = "black") +
  labs(title = "Figure 4: Type of Housing Count Plot", x = "Category", y = "Count") +
  theme_minimal()

neighborhood_Price <- data_clean[11:12]
summary_price <- neighborhood_Price %>%
  group_by(neighbourhood_cleansed) %>%
  summarise(mean_price = mean(price),
            median_price = median(price),
            min_price = min(price),
            max_price = max(price),
            total_listings = n())

summary_price <- as.data.frame(summary_price[0:30,])

stargazer(summary_price,type='latex', summary=F, title = "Figure 5: Summary Stat by Neighborhood")


```

# 3. Frequentist Analysis

<!-- Perform the frequentist analysis in this session. -->

## 3.1 Proposed Frequentist Model(s)

<!-- In this section, formulate the frequentist model(s) you are going to use to analyze your dataset. Be sure to first define the notations involved in the model(s). -->

We will be using Multiple Linear Regression to analyze our dataset. 

$$ Y = \beta_0 + \beta_1 X_1 + \dots + \beta_n X_n + \epsilon$$
* Y is the predicted rent price
* $\beta_0$ is the intercept
* $\beta_1, \dots, \beta_n$ are the coefficients for the respective $X_n$ independent variables
* $\epsilon$ is the error term

The variables that we included in our model were:
* "area", the New York neighborhood of the Airbnb listing
* "accommodates", the number of individuals the Airbnb can accommodate
* "beds", the number of beds in the Airbnb
* "bathrooms"
* "min_nights", the minimum number of nights required to book the Airbnb
* "room_type", whether the Airbnb listing was a private room, shared room, hotel room, or the entire home/apartment

## 3.2 Fitting the Frequentist Model(s)

<!-- In this section,  -->
<!-- * discuss how you fit the proposed frequentist model(s). -->
<!-- * report the results. -->
<!-- * interpret the results in the context. -->

```{r data, echo=F}
airbnb24 <- read.csv('ny_ny.24.csv')
```

```{r 2024 fit, echo=F}
lm24 = lm(price ~ area + accommodates + bathrooms + min_nights + room_type + beds, data=airbnb24)
log24 = lm(log(price) ~ area + accommodates + bathrooms + min_nights + room_type + beds, data=airbnb24)
airbnb24$logP <- log(airbnb24$price)

UES <- subset(airbnb24, area == "Upper East Side")

lm1 = lm(logP ~ area*log(accommodates) + area*bathrooms + area*log(min_nights) + area*room_type + area*beds, data=airbnb24)
lmUES = lm(logP ~ log(accommodates) + bathrooms + log(min_nights) + room_type + beds, data=UES)
lm2 = lm(logP ~ area*log(accommodates) + area*bathrooms + area*log(min_nights) + area*room_type + area*beds, data=airbnb24)
```

We fit the model by first testing if the model needed a log transformation. Thus, we graphed area vs. Price and area vs. log(Price).

```{r, echo=F}
## Residuals vs. Y
ggplot(airbnb24, aes(x=area, y=price)) + geom_point() +
  xlab("Area") + ylab("Price") + labs(title="Area vs. Price")
ggplot(airbnb24, aes(x=area, y=logP)) + geom_point() +
  xlab("Area") + ylab("Log of Price") + labs(title="Area vs. Log(Price)")
```

From the graphs above, we can see that after performing a log transformation on Price, the data becomes more linear and variance becomes more constant. 

This is further demonstrated if we graph the fitted values against the residuals.

```{r, echo=F}
## Residuals vs. fitted values
ggplot(airbnb24, aes(x=lm24$fit, y=lm24$res)) + geom_point() +
  xlab("Fitted Values") + ylab("Residuals") + labs(title = "Without Log Transformation") +
  geom_hline(yintercept = 0, col=2)
ggplot(airbnb24, aes(x=log24$fit, y=log24$res)) + geom_point() +
  xlab("Log Fitted Values") + ylab("Residuals") + labs(title = "With Log Transformation") +
  geom_hline(yintercept = 0, col=2)
```

Thus, we decided to go with log(Price) in fitting our final model. 

We included interaction terms between *area* and all other independent variables in the fitted model, and took the log of *accommodates* and *min_nights*. Looking at the R-squared values, we can see a general comparison between the model without a log transformation (lm24), the model with a log transformation (log24), and the final model we arrived at with a log transformation and interaction terms (lm1). 

```{r, echo=F, results='hide'}
summary(lm1)$r.squared
summary(log24)$r.squared
summary(lm24)$r.squared
```

Model | R^2
---------- | ------
lm24 | 0.148
log24 | 0.416
lm1 | 0.506

Given that there are 32 neighborhoods in our sample, we will not display the final equation of the fitted model as there are 288 coefficients, but we will briefly explain our results below.

In our final fitted model, the intercept $\beta_0$ = 4.328, which means if the Airbnb could accommodate 0 people, had 0 beds and bathrooms, required 0 minimum nights to book, was the entire home or apartment, and was located in Battery Park, the estimated rent price of the Airbnb is $75.78. We also found that the rent price of the Airbnb increases when it can accommodate more people, has more bathrooms, or is a private room and decreases the more minimum nights are required to book, is a hotel room or shared room, or has more beds. 

As for the neighborhoods, we found that, compared to Battery Park, the neighborhoods that increased the rent price of an Airbnb the greatest were Civic Center, Inwood, Morningside Heights, and Roosevelt Island, and the neighborhoods that decreased the rent price the greatest were Flatiron District, Grammercy, and Stuyvesant Town. 

<!-- To get a general visualization of what the model looks like, please see below for if the Airbnb was located on the Upper East Side: -->

<!-- Log(rent price) $= 4.284 + 0.333\times\log(\text{accommodates}) + 0.435\times\text{bathrooms} + 0.027\times\text{beds} - 0.024\times\text{log(min_nights)} - 0.031\times\text{private room}- 0.491*\text{shared room}$ -->

# 4. Bayesian Analysis

<!-- Propose the Bayesian analysis you will work on during the rest of the quarter in this session. -->

## 4.1 Proposed Bayesian Model(s)

<!-- In this section,  -->

<!-- * formulate the Bayesian model(s) you are going to use to analyze your dataset. Be sure to first define the notations involved in the model(s). -->
<!-- * discuss how you will elicit the prior(s). -->

We do not know exactly what Bayesian model(s) we are going to use to analyze our dataset since we do not know how to handle multiple independent variables. As for obtaining the prior, we have data from 2023 that we can use in order to obtain a prior for our analysis. 

## 4.2 Fitting the Bayesian model(s)

* Propose how you will fit the proposed Bayesian models.

* Propose how you will perform sensitivity analysis of the Bayesian models, i.e., how the posterior distribution is affected by the prior

* Propose how you will check the MCMC convergence.

## 4.3 Prediction

In this section, propose how you can make predictions using the Bayesian model.

# 5. Discussion

<!-- In this section, discuss how you can improve your model. -->

We can improve our model by narrowing down the neighborhoods where we do not have enough information in order to make reliable predictions and remove it from our model. While this means that we will have to exclude predictions for that area, that could potentially help in obtaining a better fitted model. 

# 6. Contributions

<!-- In this section, discuss the percentage of your contributions to the development final project proposal. Report the number of hours you have worked on the proposal, and the sections you are involved. -->

<!-- Please also discuss briefly the contributions of your teammate(s), as well as the help and support you got from your teammates(s). -->

Brigette and Jake contribtued to the project equally, with Jake doing sections 1 and 2, and Brigette doing sections 3, 4, and 5. We worked on the proposal for 10+ hours. 

# References

<div id="refs"></div>

# Appendix

**From Section 2:**

```{r, results='hide', fig.show='hide'}
data <- read.csv('nydata.csv')

numerical_features <- data[3:9]
categorical_features <- data[10:11]
price <- data$price
summary(price)
summary(numerical_features)

features <- c("latitude", "longitude", "accommodates", "beds", "minimum_nights", "number_of_reviews", "review_scores_rating")

for (i in 1:ncol(numerical_features)) {
  p <- ggplot(numerical_features, aes(x = numerical_features[[i]])) +
    geom_density(fill = "skyblue", color = "black") +
    labs(title = paste("Density Plot of Feature", features[i]), x = features[i], y = "Density") +
    theme_minimal()
  
  plot(p)  # Print each plot
}

#clean data
data_clean = subset(data,price <= 500 & minimum_nights <= 30)
numerical_features_clean <- data_clean[3:9]
categorical_features_clean <- data_clean[10:11]
price_clean <- data_clean$price

summary(price_clean)
summary(numerical_features_clean)

#graph again 
for (i in 1:ncol(numerical_features_clean)) {
  p <- ggplot(numerical_features_clean, aes(x = numerical_features_clean[[i]])) +
    geom_density(fill = "skyblue", color = "black") +
    labs(title = paste("Density Plot of Feature", features[i]), x = features[i], y = "Density") +
    theme_minimal()
  
  print(p)  # Print each plot
}
plot(price_clean)

pairs(numerical_features_clean)
cor_matrix <- cor(numerical_features_clean)
cor_matrix
ggcorrplot(cor_matrix)

#graphs with the categorical features 
ggplot(categorical_features_clean, aes(x = categorical_features_clean$room_type)) +
  geom_bar(stat = "count", fill = "skyblue", color = "black") +
  labs(title = "Count Plot", x = "Category", y = "Count") +
  theme_minimal()

neighborhood_Price <- data_clean[11:12]
summary_price <- neighborhood_Price %>%
  group_by(neighbourhood_cleansed) %>%
  summarise(mean_price = mean(price),
            median_price = median(price),
            min_price = min(price),
            max_price = max(price),
            total_listings = n())

summary_price
```

**From Section 3.2**

```{r, results='hide', fig.show='hide'}
airbnb24 <- read.csv('ny_ny.24.csv')
airbnb24$logP <- log(airbnb24$price)

lm24 = lm(price ~ area + accommodates + bathrooms + min_nights + room_type + beds, data=airbnb24)
log24 = lm(logP ~ area + accommodates + bathrooms + min_nights + room_type + beds, data=airbnb24)

lm1 = lm(logP ~ area*log(accommodates) + area*bathrooms + area*log(min_nights) + area*room_type + area*beds, data=airbnb24)

## Residuals vs. Y
ggplot(airbnb24, aes(x=area, y=price)) + geom_point() +
  xlab("Area") + ylab("Price") + labs(title="Area vs. Price")
ggplot(airbnb24, aes(x=area, y=logP)) + geom_point() +
  xlab("Area") + ylab("Log of Price") + labs(title="Area vs. Log(Price)")

## Residuals vs. fitted values
ggplot(airbnb24, aes(x=lm24$fit, y=lm24$res)) + geom_point() +
  xlab("Fitted Values") + ylab("Residuals") + labs(title = "Without Log Transformation") +
  geom_hline(yintercept = 0, col=2)
ggplot(airbnb24, aes(x=log24$fit, y=log24$res)) + geom_point() +
  xlab("Log Fitted Values") + ylab("Residuals") + labs(title = "With Log Transformation") +
  geom_hline(yintercept = 0, col=2)

summary(lm1)$r.squared
summary(log24)$r.squared
summary(lm24)$r.squared

coef(lm1)[1]  #log(price)
tidy(lm1)
tidy(lmUES)
```